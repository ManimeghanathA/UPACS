{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53518039",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-02T21:15:04.324314Z",
     "iopub.status.busy": "2025-09-02T21:15:04.324029Z",
     "iopub.status.idle": "2025-09-02T21:15:06.131233Z",
     "shell.execute_reply": "2025-09-02T21:15:06.130343Z"
    },
    "papermill": {
     "duration": 1.817688,
     "end_time": "2025-09-02T21:15:06.132894",
     "exception": false,
     "start_time": "2025-09-02T21:15:04.315206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/physionet-ecg/scg_rhc_f16.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbe6529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T21:15:20.760541Z",
     "iopub.status.busy": "2025-09-02T21:15:20.760124Z",
     "iopub.status.idle": "2025-09-02T21:16:11.940869Z",
     "shell.execute_reply": "2025-09-02T21:16:11.939817Z"
    },
    "papermill": {
     "duration": 51.191857,
     "end_time": "2025-09-02T21:16:11.942514",
     "exception": false,
     "start_time": "2025-09-02T21:15:20.750657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet: /kaggle/input/physionet-ecg/scg_rhc_f16.parquet\n",
      "Loaded parquet: /kaggle/input/physionet-ecg/scg_rhc_f16.parquet shape: (374, 20)\n",
      "Using ECG column: ECG_lead_II\n",
      "ECG sample counts per row â€” min/median/max: 7500 7500 7500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e51dd3f7214461f93cd71684809b9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Records:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature windows: (148, 14)\n",
      "Using numeric features: ['mean_hr', 'sdnn', 'rmssd', 'pnn50', 'sd1', 'sd2', 'lf', 'hf', 'lf_hf', 'total_power']\n",
      "Windows after cleaning: 148  raw_windows: 148\n",
      "Silhouette score (k=3): 0.418\n",
      "Cluster centers:\n",
      "      mean_hr         sdnn        rmssd     pnn50          sd1          sd2  \\\n",
      "0  35.054123  1008.298631  1348.083816  0.905750   949.956762  1054.452711   \n",
      "1  28.656391  1379.848841  1733.567958  0.953869  1222.582365  1476.074905   \n",
      "2  41.217083   625.702350   854.070917  0.777838   602.627973   640.384940   \n",
      "\n",
      "              lf             hf      lf_hf   total_power  \n",
      "0  152012.988432  156448.221074   1.368202  5.030918e+05  \n",
      "1  562998.273475  107734.185549  10.616380  1.022205e+06  \n",
      "2   58508.085515   60523.649095   1.682025  1.788265e+05  \n",
      "Windows total: 148 Train windows: 118 Test windows: 30\n",
      "Starting small random search over XGBoost parameter space (24 trials)\n",
      "  tried 6 / 24 - current best MAE (cv) = 0.1141\n",
      "  tried 12 / 24 - current best MAE (cv) = 0.1095\n",
      "  tried 18 / 24 - current best MAE (cv) = 0.1066\n",
      "  tried 24 / 24 - current best MAE (cv) = 0.1066\n",
      "Random search finished. trials run: 24\n",
      "Best CV MAE on train folds: 0.10658798339380615\n",
      "Best params: {'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 800, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 0.001, 'reg_lambda': 1.0}\n",
      "[Final XGB] Test MAE: 0.0569 | R2: 0.9303\n",
      "Top features by XGBoost gain (partial):\n",
      "  rmssd: 0.8488\n",
      "  sdnn: 0.3152\n",
      "  total_power: 0.2111\n",
      "  sd2: 0.0582\n",
      "  lf: 0.0477\n",
      "  lf_hf: 0.0453\n",
      "  hf: 0.0321\n",
      "  mean_hr: 0.0220\n",
      "  sd1: 0.0179\n",
      "  pnn50: 0.0076\n",
      "Saved artifacts to outputs\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Install dependencies (run once)\n",
    "# ===============================\n",
    "# (Uncomment if you need to install)\n",
    "# !pip install --quiet neurokit2 xgboost joblib scikit-learn scipy tqdm\n",
    "\n",
    "# ===============================\n",
    "# Full, robust HRV -> XGBoost pipeline\n",
    "# ===============================\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import resample, welch, butter, filtfilt, iirnotch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# ---------- reproducibility ----------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ---------- paths & params ----------\n",
    "PQ_PATH = \"/kaggle/input/physionet-ecg/scg_rhc_f16.parquet\"\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_RECS = 374         # set how many records to use (use 374 to use all)\n",
    "WIN_S = 30             # window length in seconds\n",
    "HOP_S = 15             # hop in seconds\n",
    "CANDIDATE_FS = [125, 250, 360, 500]\n",
    "TARGET_FS = 250        # not strictly required for XGB, but useful if you also want fixed-length windows\n",
    "\n",
    "print(\"Loading parquet:\", PQ_PATH)\n",
    "df = pd.read_parquet(PQ_PATH)\n",
    "print(\"Loaded parquet:\", PQ_PATH, \"shape:\", df.shape)\n",
    "\n",
    "# choose ECG column\n",
    "preferred = [\"ECG_lead_II\", \"ECG_lead_ii\", \"ECG_lead_II \", \"ECG_lead_I\", \"ecg_lead_ii\"]\n",
    "ecg_col = None\n",
    "for p in preferred:\n",
    "    if p in df.columns:\n",
    "        ecg_col = p\n",
    "        break\n",
    "if ecg_col is None:\n",
    "    for c in df.columns:\n",
    "        if \"ecg\" in c.lower():\n",
    "            ecg_col = c\n",
    "            break\n",
    "if ecg_col is None:\n",
    "    raise RuntimeError(\"No ECG column found in parquet.\")\n",
    "print(\"Using ECG column:\", ecg_col)\n",
    "\n",
    "# ---------------------------\n",
    "# helper: filters & fs estimation\n",
    "# ---------------------------\n",
    "def bandpass(sig, fs, low=0.5, high=40, order=4):\n",
    "    b, a = butter(order, [low/(fs/2), high/(fs/2)], btype='band')\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def notch(sig, fs, freq=50.0, q=30.0):\n",
    "    b, a = iirnotch(freq/(fs/2), q)\n",
    "    return filtfilt(b, a, sig)\n",
    "\n",
    "def estimate_fs_for_signal(arr, candidates=CANDIDATE_FS):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    best_fs = None\n",
    "    best_score = 1e9\n",
    "    for fs in candidates:\n",
    "        try:\n",
    "            peaks_info = nk.ecg_peaks(arr, sampling_rate=fs)[1]\n",
    "            peaks = peaks_info.get(\"ECG_R_Peaks\", [])\n",
    "            if len(peaks) < 3:\n",
    "                continue\n",
    "            rr = np.diff(peaks) / fs\n",
    "            mean_hr = 60.0 / rr.mean()\n",
    "            score = 0 if (40 <= mean_hr <= 140) else abs(mean_hr - 80)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_fs = fs\n",
    "        except Exception:\n",
    "            continue\n",
    "    return best_fs\n",
    "\n",
    "# ---------------------------\n",
    "# robust HRV feature extraction per window\n",
    "# returns dict or None\n",
    "# ---------------------------\n",
    "def extract_hrv_features_from_window(w, fs):\n",
    "    w = np.asarray(w, dtype=float)\n",
    "    if w.size == 0 or np.max(np.abs(w)) < 1e-6:\n",
    "        return None\n",
    "    # try clean/filter\n",
    "    try:\n",
    "        wf = bandpass(w, fs)\n",
    "        wf = notch(wf, fs, freq=50.0)\n",
    "    except Exception:\n",
    "        wf = w.copy()\n",
    "    # R-peak detection\n",
    "    try:\n",
    "        signals, info = nk.ecg_process(wf, sampling_rate=fs)\n",
    "        rpeaks = np.array(info.get(\"ECG_R_Peaks\", []))\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        rpeaks = np.array(nk.ecg_peaks(wf, sampling_rate=fs)[1].get(\"ECG_R_Peaks\", []))\n",
    "    if len(rpeaks) < 4:\n",
    "        return None\n",
    "    rr_s = np.diff(rpeaks) / fs            # in seconds\n",
    "    if rr_s.size < 2:\n",
    "        return None\n",
    "    rr_ms = rr_s * 1000.0                  # ms\n",
    "\n",
    "    out = {}\n",
    "    out['mean_hr'] = float(60.0 / rr_s.mean())\n",
    "    out['sdnn'] = float(np.std(rr_ms, ddof=1))\n",
    "    # RMSSD & pNN50\n",
    "    if rr_ms.size >= 2:\n",
    "        diff_rr = np.diff(rr_ms)\n",
    "        out['rmssd'] = float(np.sqrt(np.mean(diff_rr**2)))\n",
    "        out['pnn50'] = float(np.mean(np.abs(diff_rr) > 50.0))\n",
    "    else:\n",
    "        out['rmssd'] = np.nan\n",
    "        out['pnn50'] = np.nan\n",
    "    # Poincare SD1 / SD2\n",
    "    if rr_ms.size >= 2:\n",
    "        sd1 = np.sqrt(0.5) * np.std(np.diff(rr_ms))\n",
    "        sd1sq = sd1**2\n",
    "        sdnn = out['sdnn']\n",
    "        sd2sq = max(0.0, 2.0 * (sdnn**2) - sd1sq)\n",
    "        sd2 = math.sqrt(sd2sq)\n",
    "        out['sd1'] = float(sd1)\n",
    "        out['sd2'] = float(sd2)\n",
    "    else:\n",
    "        out['sd1'] = np.nan\n",
    "        out['sd2'] = np.nan\n",
    "\n",
    "    # Frequency domain via resampled tachogram -> Welch\n",
    "    try:\n",
    "        # times corresponding to each rr interval (use time at the end of each RR)\n",
    "        times = rpeaks[1:] / float(fs)\n",
    "        if len(times) >= 4:\n",
    "            fs_interp = 4.0\n",
    "            # create interp grid (ensure there is at least a few points)\n",
    "            t0, t1 = times[0], times[-1]\n",
    "            if t1 - t0 < 1.0:\n",
    "                # fallback to small uniform grid\n",
    "                t_interp = np.linspace(t0, t1, max(4, int((t1 - t0) * fs_interp)))\n",
    "            else:\n",
    "                t_interp = np.arange(t0, t1, 1.0 / fs_interp)\n",
    "                if len(t_interp) < 4:\n",
    "                    t_interp = np.linspace(t0, t1, max(4, int((t1 - t0) * fs_interp)))\n",
    "            rr_interp = np.interp(t_interp, times, rr_ms)\n",
    "            rr_interp = rr_interp - np.mean(rr_interp)\n",
    "            nperseg = min(256, len(rr_interp))\n",
    "            fxx, pxx = welch(rr_interp, fs=fs_interp, nperseg=nperseg)\n",
    "            # LF: 0.04-0.15 Hz, HF: 0.15-0.4 Hz\n",
    "            lf_mask = (fxx >= 0.04) & (fxx < 0.15)\n",
    "            hf_mask = (fxx >= 0.15) & (fxx < 0.4)\n",
    "            lf = float(np.trapz(pxx[lf_mask], fxx[lf_mask])) if lf_mask.any() else 0.0\n",
    "            hf = float(np.trapz(pxx[hf_mask], fxx[hf_mask])) if hf_mask.any() else 0.0\n",
    "            total_mask = (fxx >= 0.003) & (fxx < 0.4)\n",
    "            total_power = float(np.trapz(pxx[total_mask], fxx[total_mask])) if total_mask.any() else (lf + hf)\n",
    "            out['lf'] = lf\n",
    "            out['hf'] = hf\n",
    "            out['lf_hf'] = float(lf / hf) if (hf is not None and hf > 0) else np.nan\n",
    "            out['total_power'] = total_power\n",
    "        else:\n",
    "            out['lf'] = np.nan; out['hf'] = np.nan; out['lf_hf'] = np.nan; out['total_power'] = np.nan\n",
    "    except Exception:\n",
    "        out['lf'] = np.nan; out['hf'] = np.nan; out['lf_hf'] = np.nan; out['total_power'] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# 4) sliding windows + feature extraction\n",
    "# ---------------------------\n",
    "features = []\n",
    "raw_windows = []\n",
    "max_recs = min(MAX_RECS, len(df))\n",
    "lengths = [len(np.asarray(a, float)) for a in df[ecg_col]]\n",
    "print(\"ECG sample counts per row â€” min/median/max:\",\n",
    "      int(np.min(lengths)), int(np.median(lengths)), int(np.max(lengths)))\n",
    "\n",
    "for idx in tqdm(range(max_recs), desc=\"Records\"):\n",
    "    arr = np.asarray(df[ecg_col].iloc[idx], dtype=float)\n",
    "    fs = estimate_fs_for_signal(arr)\n",
    "    if fs is None:\n",
    "        # skip unusable record\n",
    "        continue\n",
    "    npts = arr.size\n",
    "    win_pts = int(WIN_S * fs)\n",
    "    hop_pts = int(HOP_S * fs)\n",
    "    if npts < win_pts:\n",
    "        continue\n",
    "    for start in range(0, npts - win_pts + 1, hop_pts):\n",
    "        w = arr[start:start + win_pts]\n",
    "        feats = extract_hrv_features_from_window(w, fs)\n",
    "        if feats is None:\n",
    "            continue\n",
    "        rec = {\"rec_index\": int(idx), \"start_sample\": int(start), \"fs\": int(fs), \"n_samples\": int(len(w))}\n",
    "        rec.update(feats)\n",
    "        features.append(rec)\n",
    "        # store optionally the resampled window if you want DL later\n",
    "        raw_windows.append(resample(w, int(round(len(w) * (TARGET_FS / fs)))))\n",
    "\n",
    "feats_df = pd.DataFrame(features)\n",
    "print(\"Extracted feature windows:\", feats_df.shape)\n",
    "if feats_df.shape[0] == 0:\n",
    "    raise RuntimeError(\"No valid windows found; check ECG data and sampling rate detection.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Feature cleanup & selected feature columns\n",
    "# ---------------------------\n",
    "candidate_cols = ['mean_hr', 'sdnn', 'rmssd', 'pnn50', 'sd1', 'sd2', 'lf', 'hf', 'lf_hf', 'total_power']\n",
    "# keep only columns that exist\n",
    "candidate_cols = [c for c in candidate_cols if c in feats_df.columns]\n",
    "print(\"Using numeric features:\", candidate_cols)\n",
    "\n",
    "feats_df_clean = feats_df.dropna(subset=['mean_hr', 'sdnn']).reset_index(drop=True)  # ensure core features present\n",
    "# fill other nans with median\n",
    "for c in candidate_cols:\n",
    "    if feats_df_clean[c].isna().any():\n",
    "        feats_df_clean[c] = feats_df_clean[c].fillna(feats_df_clean[c].median())\n",
    "\n",
    "raw_windows_clean = np.array(raw_windows, dtype=object)\n",
    "# align raw_windows to feats_df_clean indices (we appended in lock-step so slicing is okay)\n",
    "if len(raw_windows_clean) != len(feats_df):\n",
    "    # if differing, try to align using valid_mask\n",
    "    valid_mask = feats_df[candidate_cols].notna().all(axis=1).values\n",
    "    raw_windows_clean = raw_windows_clean[valid_mask]\n",
    "else:\n",
    "    # apply same dropna mask used above\n",
    "    mask = feats_df.index[feats_df[['mean_hr', 'sdnn']].notna().all(axis=1)]\n",
    "    raw_windows_clean = raw_windows_clean[mask]\n",
    "\n",
    "print(\"Windows after cleaning:\", feats_df_clean.shape[0], \" raw_windows:\", raw_windows_clean.shape[0])\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Unsupervised clustering -> pseudo labels (k=3) same approach as your baseline\n",
    "# ---------------------------\n",
    "X = feats_df_clean[candidate_cols].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k = 3\n",
    "km = xgb.sklearn = None  # avoid name collision (we will import KMeans)\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=k, random_state=SEED, n_init=20)\n",
    "labels = km.fit_predict(X_scaled)\n",
    "sil = silhouette_score(X_scaled, labels)\n",
    "print(\"Silhouette score (k=3):\", round(sil, 3))\n",
    "\n",
    "centers_df = pd.DataFrame(scaler.inverse_transform(km.cluster_centers_), columns=candidate_cols)\n",
    "print(\"Cluster centers:\\n\", centers_df)\n",
    "\n",
    "# map cluster -> pseudo_depth by SDNN (desc -> light=0)\n",
    "order = centers_df.sort_values('sdnn', ascending=False).index.tolist()\n",
    "cluster_to_depth = {c: i for i, c in enumerate(order)}\n",
    "feats_df_clean['cluster'] = labels\n",
    "feats_df_clean['pseudo_depth'] = feats_df_clean['cluster'].map(cluster_to_depth).astype(float)\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Group-aware train/test split (preserve rec_index grouping)\n",
    "# ---------------------------\n",
    "groups = feats_df_clean['rec_index'].values\n",
    "X_mat = feats_df_clean[candidate_cols].values\n",
    "y = feats_df_clean['pseudo_depth'].values\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X_mat, y, groups))\n",
    "X_train, X_test = X_mat[train_idx], X_mat[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "groups_train = groups[train_idx]\n",
    "\n",
    "print(\"Windows total:\", len(y), \"Train windows:\", len(y_train), \"Test windows:\", len(y_test))\n",
    "\n",
    "# scale using scaler fitted above (X_scaled corresponds to whole dataset)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Light random search of XGBoost hyperparameters (on training folds only)\n",
    "# ---------------------------\n",
    "def cv_mean_mae_for_params(params, Xtr, ytr, groups_tr, n_splits=4):\n",
    "    # use GroupKFold on training records\n",
    "    n_groups = len(np.unique(groups_tr))\n",
    "    n_splits = min(n_splits, n_groups) if n_groups >= 2 else 2\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    maes = []\n",
    "    for tr_idx, val_idx in gkf.split(Xtr, ytr, groups_tr):\n",
    "        model = xgb.XGBRegressor(random_state=SEED, n_jobs=1, **params)\n",
    "        model.fit(Xtr[tr_idx], ytr[tr_idx])\n",
    "        preds = model.predict(Xtr[val_idx])\n",
    "        maes.append(mean_absolute_error(ytr[val_idx], preds))\n",
    "    return np.mean(maes)\n",
    "\n",
    "# parameter search space (small, safe)\n",
    "param_choices = {\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"n_estimators\": [100, 200, 400, 800],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 1e-3, 1e-2],\n",
    "    \"reg_lambda\": [1.0, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "# sample a set of candidate configs randomly (safe count)\n",
    "n_trials = 24\n",
    "best_mae = 1e9\n",
    "best_params = None\n",
    "tried = 0\n",
    "print(\"Starting small random search over XGBoost parameter space ({} trials)\".format(n_trials))\n",
    "for _ in range(n_trials):\n",
    "    params = {\n",
    "        \"max_depth\": random.choice(param_choices[\"max_depth\"]),\n",
    "        \"learning_rate\": random.choice(param_choices[\"learning_rate\"]),\n",
    "        \"n_estimators\": random.choice(param_choices[\"n_estimators\"]),\n",
    "        \"subsample\": random.choice(param_choices[\"subsample\"]),\n",
    "        \"colsample_bytree\": random.choice(param_choices[\"colsample_bytree\"]),\n",
    "        \"reg_alpha\": random.choice(param_choices[\"reg_alpha\"]),\n",
    "        \"reg_lambda\": random.choice(param_choices[\"reg_lambda\"]),\n",
    "    }\n",
    "    try:\n",
    "        mae_cv = cv_mean_mae_for_params(params, X_train_scaled, y_train, groups_train, n_splits=4)\n",
    "    except Exception as e:\n",
    "        print(\"Trial failed:\", e)\n",
    "        continue\n",
    "    tried += 1\n",
    "    if mae_cv < best_mae:\n",
    "        best_mae = mae_cv\n",
    "        best_params = params\n",
    "    if tried % 6 == 0:\n",
    "        print(f\"  tried {tried} / {n_trials} - current best MAE (cv) = {best_mae:.4f}\")\n",
    "print(\"Random search finished. trials run:\", tried)\n",
    "print(\"Best CV MAE on train folds:\", best_mae)\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "# if tuning failed for some reason, fall back to reasonable defaults\n",
    "if best_params is None:\n",
    "    best_params = {\"max_depth\":5, \"learning_rate\":0.05, \"n_estimators\":400, \"subsample\":0.9, \"colsample_bytree\":0.9, \"reg_alpha\":0.0, \"reg_lambda\":1.0}\n",
    "    print(\"Using fallback params:\", best_params)\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Train final XGB on train set and evaluate on test set\n",
    "# ---------------------------\n",
    "final_model = xgb.XGBRegressor(random_state=SEED, n_jobs=1, **best_params)\n",
    "final_model.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "test_r2  = r2_score(y_test, test_preds)\n",
    "print(\"[Final XGB] Test MAE: {:.4f} | R2: {:.4f}\".format(test_mae, test_r2))\n",
    "\n",
    "# feature importance (by gain)\n",
    "try:\n",
    "    imp = final_model.get_booster().get_score(importance_type='gain')\n",
    "    # map back to column names\n",
    "    fi = {candidate_cols[int(k.replace('f',''))]: v for k, v in imp.items() if k.startswith('f')}\n",
    "    print(\"Top features by XGBoost gain (partial):\")\n",
    "    # sort descending\n",
    "    for k,v in sorted(fi.items(), key=lambda x: -x[1])[:10]:\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# save artifacts\n",
    "joblib.dump(final_model, os.path.join(OUT_DIR, \"xgb_final_model.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(OUT_DIR, \"hrv_scaler.pkl\"))\n",
    "joblib.dump({\"candidate_cols\": candidate_cols, \"best_params\": best_params}, os.path.join(OUT_DIR, \"meta.pkl\"))\n",
    "print(\"Saved artifacts to\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8188535,
     "sourceId": 12939936,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.565002,
   "end_time": "2025-09-02T21:16:12.771143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-02T21:14:59.206141",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04df3648c86546bd95944fa44f1c2170": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90adda56bee4462d9f05aae75a083c9d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0d8748878b724d06a56b4ff2bc1b14d6",
       "tabbable": null,
       "tooltip": null,
       "value": "Records:â€‡100%"
      }
     },
     "0c45c191942b48349912238f161863aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0d8748878b724d06a56b4ff2bc1b14d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f6ca2f2375e48b7b1eccd804a770c10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e51dd3f7214461f93cd71684809b9cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_04df3648c86546bd95944fa44f1c2170",
        "IPY_MODEL_9ce50f1efcee4c7394125ed7e6b4c096",
        "IPY_MODEL_5e9bea9086024ea98643e23fa9a1eddf"
       ],
       "layout": "IPY_MODEL_e20c9e41c3b8454db27f73036c2717b6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3ca1508d76fd45529f8683f694ce4b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "574911fd21fe42749ff3f97f2206ae42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e9bea9086024ea98643e23fa9a1eddf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f6ca2f2375e48b7b1eccd804a770c10",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0c45c191942b48349912238f161863aa",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡374/374â€‡[00:37&lt;00:00,â€‡10.47it/s]"
      }
     },
     "90adda56bee4462d9f05aae75a083c9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ce50f1efcee4c7394125ed7e6b4c096": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_574911fd21fe42749ff3f97f2206ae42",
       "max": 374,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ca1508d76fd45529f8683f694ce4b4e",
       "tabbable": null,
       "tooltip": null,
       "value": 374
      }
     },
     "e20c9e41c3b8454db27f73036c2717b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
